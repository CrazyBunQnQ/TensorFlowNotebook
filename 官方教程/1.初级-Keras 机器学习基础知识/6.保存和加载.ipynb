{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZJ3uY9O17VN"
   },
   "source": [
    "# 保存和恢复模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBdde4YJeJKF"
   },
   "source": [
    "可以在训练期间和之后保存模型进度。这意味着模型可以从停止的地方恢复，避免长时间的训练。此外，保存还意味着您可以分享您的模型，其他人可以重现您的工作。在发布研究模型和技术时，大多数机器学习从业者会分享：\n",
    "\n",
    "- 用于创建模型的代码\n",
    "- 模型训练的权重 (weight) 和参数 (parameters) 。\n",
    "\n",
    "共享数据有助于其他人了解模型的工作原理，并使用新数据自行尝试。\n",
    "\n",
    "小心：TensorFlow 模型是代码，对于不受信任的代码，一定要小心。请参阅 [安全使用 TensorFlow](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) 以了解详情。\n",
    "\n",
    "### 选项\n",
    "\n",
    "根据您使用的 API，可以通过多种方式保存 TensorFlow 模型。本指南使用 [tf.keras](https://tensorflow.google.cn/guide/keras)，这是一种在 TensorFlow 中构建和训练模型的高级 API。对于其他方式，请参阅 TensorFlow [保存和恢复](https://tensorflow.google.cn/guide/saved_model)指南或[在 Eager 中保存](https://tensorflow.google.cn/guide/eager#object-based_saving)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCUREq7WXgvg"
   },
   "source": [
    "## 配置\n",
    "\n",
    "### 安装并导入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7l0MiTOrXtNv"
   },
   "source": [
    "导入Tensorflow和依赖项："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7Nm7Tyb-gRt-",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "# pip install pyyaml h5py  # Required to save models in HDF5 format\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbGsznErXWt6"
   },
   "source": [
    "### 获取示例数据集\n",
    "\n",
    "为了演示如何保存和加载权重，您将使用 [MNIST 数据集](http://yann.lecun.com/exdb/mnist/)。为了加快运行速度，请使用前 1000 个样本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9rGfFwE9XVwz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anG3iVoXyZGI"
   },
   "source": [
    "### 定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wynsOBfby0Pa"
   },
   "source": [
    "首先构建一个简单的序列（sequential）模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0HZbJIjxyX1S",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 定义一个简单的序列模型\n",
    "def create_model():\n",
    "  model = tf.keras.models.Sequential([\n",
    "    keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10)\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer='adam',\n",
    "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "  return model\n",
    "\n",
    "# 创建基本模型实例\n",
    "model = create_model()\n",
    "\n",
    "# 显示模型的架构\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "soDE0W_KH8rG"
   },
   "source": [
    "## 在训练期间保存模型（以 checkpoints 形式保存）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRyd5qQQIXZm"
   },
   "source": [
    "您可以使用经过训练的模型而无需重新训练，或者在训练过程中断的情况下从离开处继续训练。`tf.keras.callbacks.ModelCheckpoint` 回调允许您在训练*期间*和*结束*时持续保存模型。\n",
    "\n",
    "### Checkpoint 回调用法\n",
    "\n",
    "创建一个只在训练期间保存权重的 `tf.keras.callbacks.ModelCheckpoint` 回调："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IFPuhwntH8VH",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 1.2733 - sparse_categorical_accuracy: 0.6332\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 1s 10ms/step - loss: 1.1243 - sparse_categorical_accuracy: 0.6760 - val_loss: 0.6988 - val_sparse_categorical_accuracy: 0.7950\n",
      "Epoch 2/10\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.4246 - sparse_categorical_accuracy: 0.8737\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4206 - sparse_categorical_accuracy: 0.8780 - val_loss: 0.5345 - val_sparse_categorical_accuracy: 0.8350\n",
      "Epoch 3/10\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.2706 - sparse_categorical_accuracy: 0.9284\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2779 - sparse_categorical_accuracy: 0.9270 - val_loss: 0.4798 - val_sparse_categorical_accuracy: 0.8510\n",
      "Epoch 4/10\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.1956 - sparse_categorical_accuracy: 0.9565\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1898 - sparse_categorical_accuracy: 0.9580 - val_loss: 0.4467 - val_sparse_categorical_accuracy: 0.8590\n",
      "Epoch 5/10\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.1460 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1477 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.4224 - val_sparse_categorical_accuracy: 0.8620\n",
      "Epoch 6/10\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 0.1088 - sparse_categorical_accuracy: 0.9808\n",
      "Epoch 00006: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1140 - sparse_categorical_accuracy: 0.9780 - val_loss: 0.4372 - val_sparse_categorical_accuracy: 0.8550\n",
      "Epoch 7/10\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.0829 - sparse_categorical_accuracy: 0.9912\n",
      "Epoch 00007: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0806 - sparse_categorical_accuracy: 0.9920 - val_loss: 0.3939 - val_sparse_categorical_accuracy: 0.8760\n",
      "Epoch 8/10\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.0666 - sparse_categorical_accuracy: 0.9912\n",
      "Epoch 00008: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0632 - sparse_categorical_accuracy: 0.9930 - val_loss: 0.4061 - val_sparse_categorical_accuracy: 0.8720\n",
      "Epoch 9/10\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.0471 - sparse_categorical_accuracy: 0.9987\n",
      "Epoch 00009: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0445 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.3850 - val_sparse_categorical_accuracy: 0.8730\n",
      "Epoch 10/10\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.0363 - sparse_categorical_accuracy: 0.9987\n",
      "Epoch 00010: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0363 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.3977 - val_sparse_categorical_accuracy: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f863491a8b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# 创建一个保存模型权重的回调\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "# 使用新回调训练模型\n",
    "model.fit(train_images, \n",
    "          train_labels,  \n",
    "          epochs=10,\n",
    "          validation_data=(test_images, test_labels),\n",
    "          callbacks=[cp_callback])  # 将回调传递给训练\n",
    "\n",
    "# 这可能会生成与保存优化器状态相关的警告。\n",
    "# 这些警告（以及本笔记本中的类似警告）就可以劝阻过时的使用，并且可以忽略。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlM-sgyJO084"
   },
   "source": [
    "这将创建一个 TensorFlow checkpoint 文件集合，这些文件在每个 epoch 结束时更新："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gXG5FVKFOVQ3",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['checkpoint', 'cp.ckpt.data-00000-of-00001', 'cp.ckpt.index']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlRN_f56Pqa9"
   },
   "source": [
    "只要两个模型共享相同的架构，您就可以在它们之间共享权重。因此，当从仅权重恢复模型时，创建一个与原始模型具有相同架构的模型，然后设置其权重。\n",
    "\n",
    "现在，重新构建一个未经训练的全新模型并基于测试集对其进行评估。未经训练的模型将以机会水平执行（约 10% 的准确率）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Fp5gbuiaPqCT",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 2.3019 - sparse_categorical_accuracy: 0.1290 - 106ms/epoch - 3ms/step\n",
      "Untrained model, accuracy: 12.90%\n"
     ]
    }
   ],
   "source": [
    "# 创建基本模型实例\n",
    "model = create_model()\n",
    "\n",
    "# 评估模型\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DTKpZssRSo3"
   },
   "source": [
    "然后从 checkpoint 加载权重并重新评估："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2IZxbwiRRSD2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.3977 - sparse_categorical_accuracy: 0.8750 - 41ms/epoch - 1ms/step\n",
      "Restored model, accuracy: 87.50%\n"
     ]
    }
   ],
   "source": [
    "# 加载权重\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# 重新评估模型\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpAbKkAyVPV8"
   },
   "source": [
    "### checkpoint 回调选项\n",
    "\n",
    "回调提供了几个选项，为 checkpoint 提供唯一名称并调整 checkpoint 频率。\n",
    "\n",
    "训练一个新模型，每五个 epochs 保存一次唯一命名的 checkpoint ："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mQF_dlgIVOvq",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: saving model to training_2/cp-0005.ckpt\n",
      "\n",
      "Epoch 00010: saving model to training_2/cp-0010.ckpt\n",
      "\n",
      "Epoch 00015: saving model to training_2/cp-0015.ckpt\n",
      "\n",
      "Epoch 00020: saving model to training_2/cp-0020.ckpt\n",
      "\n",
      "Epoch 00025: saving model to training_2/cp-0025.ckpt\n",
      "\n",
      "Epoch 00030: saving model to training_2/cp-0030.ckpt\n",
      "\n",
      "Epoch 00035: saving model to training_2/cp-0035.ckpt\n",
      "\n",
      "Epoch 00040: saving model to training_2/cp-0040.ckpt\n",
      "\n",
      "Epoch 00045: saving model to training_2/cp-0045.ckpt\n",
      "\n",
      "Epoch 00050: saving model to training_2/cp-0050.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f861692e580>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在文件名中包含纪元（使用 `str.format`）\n",
    "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 创建一个回调，每 5 个 epoch 保存一次模型的权重\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq=5*batch_size)\n",
    "\n",
    "# 创建一个新的模型实例\n",
    "model = create_model()\n",
    "\n",
    "# 使用 `checkpoint_path` 格式保存权重\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "# 使用新回调训练模型\n",
    "model.fit(train_images, \n",
    "          train_labels,\n",
    "          epochs=50, \n",
    "          batch_size=batch_size, \n",
    "          callbacks=[cp_callback],\n",
    "          validation_data=(test_images, test_labels),\n",
    "          verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zFrKTjjavWI"
   },
   "source": [
    "现在查看生成的 checkpoint 并选择最新的 checkpoint ："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "p64q3-V4sXt0",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['checkpoint',\n",
       " 'cp-0000.ckpt.data-00000-of-00001',\n",
       " 'cp-0000.ckpt.index',\n",
       " 'cp-0005.ckpt.data-00000-of-00001',\n",
       " 'cp-0005.ckpt.index',\n",
       " 'cp-0010.ckpt.data-00000-of-00001',\n",
       " 'cp-0010.ckpt.index',\n",
       " 'cp-0015.ckpt.data-00000-of-00001',\n",
       " 'cp-0015.ckpt.index',\n",
       " 'cp-0020.ckpt.data-00000-of-00001',\n",
       " 'cp-0020.ckpt.index',\n",
       " 'cp-0025.ckpt.data-00000-of-00001',\n",
       " 'cp-0025.ckpt.index',\n",
       " 'cp-0030.ckpt.data-00000-of-00001',\n",
       " 'cp-0030.ckpt.index',\n",
       " 'cp-0035.ckpt.data-00000-of-00001',\n",
       " 'cp-0035.ckpt.index',\n",
       " 'cp-0040.ckpt.data-00000-of-00001',\n",
       " 'cp-0040.ckpt.index',\n",
       " 'cp-0045.ckpt.data-00000-of-00001',\n",
       " 'cp-0045.ckpt.index',\n",
       " 'cp-0050.ckpt.data-00000-of-00001',\n",
       " 'cp-0050.ckpt.index']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1AN_fnuyR41H",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_2/cp-0050.ckpt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zk2ciGbKg561"
   },
   "source": [
    "注：默认 TensorFlow 格式只保存最近的 5 个检查点。\n",
    "\n",
    "如果要进行测试，请重置模型并加载最新的 checkpoint ："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3M04jyK-H3QK",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4870 - sparse_categorical_accuracy: 0.8720 - 100ms/epoch - 3ms/step\n",
      "Restored model, accuracy: 87.20%\n"
     ]
    }
   ],
   "source": [
    "# 创建一个新的模型实例\n",
    "model = create_model()\n",
    "\n",
    "# 加载之前保存的权重\n",
    "model.load_weights(latest)\n",
    "\n",
    "# 重新评估模型\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2OxsJOTHxia"
   },
   "source": [
    "## 这些文件是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtdYhvWnH2ib"
   },
   "source": [
    "上述代码将权重存储到 [checkpoint](https://tensorflow.google.cn/guide/saved_model#save_and_restore_variables)—— 格式化文件的集合中，这些文件仅包含二进制格式的训练权重。 Checkpoints 包含：\n",
    "\n",
    "- 一个或多个包含模型权重的分片。\n",
    "- 一个索引文件，指示哪些权重存储在哪个分片中。\n",
    "\n",
    "如果您在一台计算机上训练模型，您将获得一个具有如下后缀的分片：`.data-00000-of-00001`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_FA-ZvxuXQV"
   },
   "source": [
    "## 手动保存权重\n",
    "\n",
    "使用 `Model.save_weights` 方法手动保存权重。默认情况下，`tf.keras`（尤其是 `save_weights`）使用扩展名为 `.ckpt` 的 TensorFlow [检查点](../../guide/checkpoint.ipynb)格式（保存在扩展名为 `.h5` 的 [HDF5](https://js.tensorflow.org/tutorials/import-keras.html) 中，[保存和序列化模型](../../guide/keras/save_and_serialize#weights-only_saving_in_savedmodel_format)指南中会讲到这一点）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "R7W5plyZ-u9X",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "32/32 - 0s - loss: 0.4870 - sparse_categorical_accuracy: 0.8720 - 98ms/epoch - 3ms/step\n",
      "Restored model, accuracy: 87.20%\n"
     ]
    }
   ],
   "source": [
    "# 保存权重\n",
    "model.save_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# 创建一个新的模型实例\n",
    "model = create_model()\n",
    "\n",
    "# 恢复权重\n",
    "model.load_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# 评估模型\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOGlxPRBEvV1"
   },
   "source": [
    "## 保存整个模型\n",
    "\n",
    "调用 [`model.save`](https://tensorflow.google.cn/api_docs/python/tf/keras/Model#save) 将保存模型的结构，权重和训练配置保存在单个文件/文件夹中。这可以让您导出模型，以便在不访问原始 Python 代码*的情况下使用它。因为优化器状态（optimizer-state）已经恢复，您可以从中断的位置恢复训练。\n",
    "\n",
    "整个模型可以保存为两种不同的文件格式（`SavedModel` 和 `HDF5`）。TensorFlow `SavedModel` 格式是 TF2.x 中的默认文件格式。但是，模型能够以 `HDF5` 格式保存。下面详细介绍了如何以两种文件格式保存整个模型。\n",
    "\n",
    "保存完整模型会非常有用——您可以在 TensorFlow.js（[Saved Model](https://tensorflow.google.cn/js/tutorials/conversion/import_saved_model), [HDF5](https://tensorflow.google.cn/js/tutorials/conversion/import_keras)）加载它们，然后在 web 浏览器中训练和运行它们，或者使用  TensorFlow Lite 将它们转换为在移动设备上运行（[Saved Model](https://tensorflow.google.cn/lite/convert/python_api#converting_a_savedmodel_), [HDF5](https://tensorflow.google.cn/lite/convert/python_api#converting_a_keras_model_)）\n",
    "\n",
    "*自定义对象（例如，子类化模型或层）在保存和加载时需要特别注意。请参阅下面的**保存自定义对象**部分 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPyhgcoVzqUB"
   },
   "source": [
    "### SavedModel 格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtcN4VIb7JkK"
   },
   "source": [
    "SavedModel 格式是另一种序列化模型的方式。以这种格式保存的模型可以使用 `tf.keras.models.load_model` 恢复，并且与 TensorFlow Serving 兼容。[SavedModel 指南](https://tensorflow.google.cn/guide/saved_model)详细介绍了如何应用/检查 SavedModel。以下部分说明了保存和恢复模型的步骤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sI1YvCDFzpl3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.1335 - sparse_categorical_accuracy: 0.6750\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4171 - sparse_categorical_accuracy: 0.8830\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2881 - sparse_categorical_accuracy: 0.9330\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2170 - sparse_categorical_accuracy: 0.9490\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1653 - sparse_categorical_accuracy: 0.9640\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "# 创建并训练一个新的模型实例。\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# 将整个模型保存为 SavedModel。\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUvT_3qE8hV5"
   },
   "source": [
    "SavedModel 格式是一个包含 protobuf 二进制文件和 TensorFlow 检查点的目录。检查保存的模型目录："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "sq8fPglI1RWA",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_model\n",
      "assets\tkeras_metadata.pb  saved_model.pb  variables\n"
     ]
    }
   ],
   "source": [
    "# my_model 目录\n",
    "!ls saved_model\n",
    "\n",
    "# 包含资产文件夹、saved_model.pb 和变量文件夹。\n",
    "!ls saved_model/my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7qfpvpY9HCe"
   },
   "source": [
    "从保存的模型重新加载一个新的 Keras 模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0YofwHdN0pxa",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('saved_model/my_model')\n",
    "\n",
    "# 检查它的架构\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWwgNaz19TH2"
   },
   "source": [
    "使用与原始模型相同的参数编译恢复的模型。尝试使用加载的模型运行评估和预测："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Yh5Mu0yOgE5J",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4140 - sparse_categorical_accuracy: 0.8630 - 108ms/epoch - 3ms/step\n",
      "Restored model, accuracy: 86.30%\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "# 评估恢复的模型\n",
    "loss, acc = new_model.evaluate(test_images, test_labels, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
    "\n",
    "print(new_model.predict(test_images).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkGwf-50zLNn"
   },
   "source": [
    "### HDF5 格式\n",
    "\n",
    "Keras使用 [HDF5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) 标准提供了一种基本的保存格式。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "m2dkmJVCGUia",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.2204 - sparse_categorical_accuracy: 0.6490\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4448 - sparse_categorical_accuracy: 0.8780\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2864 - sparse_categorical_accuracy: 0.9300\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2306 - sparse_categorical_accuracy: 0.9380\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1683 - sparse_categorical_accuracy: 0.9660\n"
     ]
    }
   ],
   "source": [
    "# 创建并训练一个新的模型实例。\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# 将整个模型保存到 HDF5 文件中。\n",
    "# '.h5' 扩展名表示模型应保存为 HDF5。\n",
    "model.save('my_model.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWmttMOqS68S"
   },
   "source": [
    "现在，从该文件重新创建模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "5NDMO_7kS6Do",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 重新创建完全相同的模型，包括其权重和优化器\n",
    "new_model = tf.keras.models.load_model('my_model.h5')\n",
    "\n",
    "# 展示模型架构\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXQpbTicTBwt"
   },
   "source": [
    "检查其准确率（accuracy）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "jwEaj9DnTCVA",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4368 - sparse_categorical_accuracy: 0.8580 - 101ms/epoch - 3ms/step\n",
      "Restored model, accuracy: 85.80%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images, test_labels, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGXqd4wWJl8O"
   },
   "source": [
    "Keras 通过检查模型的架构来保存这些模型。这种技术可以保存所有内容：\n",
    "\n",
    "- 权重值\n",
    "- 模型的架构\n",
    "- 模型的训练配置（您传递给 `.compile()` 方法的内容）\n",
    "- 优化器及其状态（如果有）（这样，您便可从中断的地方重新启动训练）\n",
    "\n",
    "Keras 无法保存 `v1.x` 优化器（来自 `tf.compat.v1.train`），因为它们与检查点不兼容。对于 v1.x 优化器，您需要在加载-失去优化器的状态后，重新编译模型。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAUKJQyGqTNH"
   },
   "source": [
    "### 保存自定义对象\n",
    "\n",
    "如果您正在使用 SavedModel 格式，则可以跳过此部分。HDF5 和 SavedModel 之间的主要区别在于，HDF5 使用对象配置来保存模型架构，而 SavedModel 则保存执行计算图。因此，SavedModel 能够在不需要原始代码的情况下保存自定义对象，如子类模型和自定义层。\n",
    "\n",
    "要将自定义对象保存到 HDF5，您必须执行以下操作：\n",
    "\n",
    "1. 在您的对象中定义一个 `get_config` 方法，并且可以选择定义一个 `from_config` 类方法。\n",
    "    - `get_config(self)` 返回重新创建对象所需的参数的 JSON 可序列化字典。\n",
    "    - `from_config(cls, config)` 使用从 `get_config` 返回的配置来创建一个新对象。默认情况下，此函数将使用配置作为初始化 kwarg (`return cls(**config)`)。\n",
    "2. 加载模型时将对象传递给 `custom_objects` 参数。参数必须是将字符串类名映射到 Python 类的字典。例如 `tf.keras.models.load_model(path, custom_objects={'CustomLayer': CustomLayer})`\n",
    "\n",
    "有关自定义对象和 `get_config` 的示例，请参阅[从头开始编写层和模型](https://tensorflow.google.cn/guide/keras/custom_layers_and_models)教程。\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "save_and_load.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
